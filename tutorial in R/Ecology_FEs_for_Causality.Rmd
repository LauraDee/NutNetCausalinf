---
title: 'Panel Data and Fixed Effects Methods for Ecology'
author: "Online tutorial for the analyses run in: Dee et al. written by Chris Severen and Laura Dee"
date: 'Last updated: `r Sys.Date()`'
output:
  bookdown::html_document2:
    smart: no
    df_print: kable
    theme: flatly
    toc: true
    toc_float: true
bibliography: [FE.bib]
biblio-style: "apalike"
link-citations: true
---
<!-- ## internal notes for how to use markdown -->

<!-- points 1 and 2 are quite easy to deal using bookdown instead of markdown. To do so you juste have to replace the "output: html_document"  with "output: bookdown::html_document2" in the yaml section.  -->

<!-- -Then, you can make references to sections using \@ref(name-of-section) where name-of-section is the section title in downcase letters and with spaces replaced by ‘-‘.  -->
<!-- -You can make references to figures using \@ref(fig:block) where block is the name of the r block that has produces the figure. Table will also work using \@ref(table:tablename). -->
<!-- - For equations, you have to label the equations using (\#eqname) inside the \begin{equation} \end{equation} block and then use  \@ref(eq:eqname) in the text -->
<!-- - For colours, I don’t know an easy solution but you can use html code directly:  -->
<!-- <div style="color: red; »> -->
<!--         This is an R Markdown document.  -->
<!-- </div> -->
<!-- will print the sentence in red.  -->
<!-- Example for making links in the doc Causal inference involves ruling out [**rival explanations**](#rivalexplanation) for an estimated relationship.

# Glossary {-}
<a name="rivalexplanation">[rival explanations](#standard-approaches)</a>

: definition for rival explanation  -->



# Setup and Load Data

The data used in this tutorial comes from the [Nutrient Network](https://nutnet.org/). It has been cleaned and processed and is ready to use. The data correspond to what we use in the paper for the main analysis, and consists of control plots from 43 NutNet sites. Each site includes one or more control plots that we use. We only use plots for which we have at least 5 years of data.

We'll primarily use the *fixest* package for analysis; the other packages (*tidyverse*, *data.table*, *lme4*) aid data wrangling and comparing research designs.
```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(fixest)
library(lme4)  # Need at least version 1.1-26
library(knitr)
library(ggplot2)

cdir <- getwd()
comb <- fread(paste(cdir,"/cleaned_comb_data.csv",sep=""),na.strings='NA')
comb$V1 = NULL
```

The *comb* dataset contains a wide number of variables; we'll mainly be using the variables *live_mass* and *rich*. Also important are the *site_code*, *plot*, and *year* variables, which we use to create fixed effects (site-by-year fixed were created with `"r comb[, site.by.yeardummy := paste(site_code, year, sep = "_")]"`).


# Standard Approaches

For causal inference, we need to answer, *how much does a change in $X$ lead to a change in $Y$*. Causal inference involves ruling out [**rival explanations**](#rivalexplanations) for an estimated relationship. This aim and requirement differs from other research tasks (e.g., predicting where total productivity will be the highest, which can be done without knowing the true underlying causes of productivity). Thus, the criteria for evaluating causal inference differ from other task. For example, prediction or forecasting of rely on model fit measures, such as R-squared values or mean squared error [see @ferraroCausalInferenceCoupled2018]. 

We evaluate causal inference by assessing the credibility and validity of the assumptions made by the research design for each dataset, system, and question [reviewed in @morganCounterfactualsCausalInference2014;@ferraroCausalInferenceCoupled2018], as we will illustrate next.  Being explicit about these assumptions and evaluating how reasonable they are is important for causal inference.

Dr. Paul Allison has an excellent [blog post](https://statisticalhorizons.com/prediction-vs-causation-in-regression-analysis) explaining why R-squared values are NOT important the important criteria for causal interpretations compared to the credibility and validity of the assumptions made by the research design. 

## Simple correlations in single years

Let's begin by looking at simple correlations. We will examine both the overall correlation and correlations within a single year (i.e., using cross-sectional variation). We proceed with a linear regression framework \@ref(eq:eq1), using the log of productivity (measured as live aboveground biomass) as the outcome and the log species richness as the explanatory variable.  We've found that a log-log specification captures the nature of the relationship in our data well (see Figure \@ref(fig:graphbiomasssp) below and the paper for details).

```{r graphbiomasssp, echo = F, out.width = '60%', fig.align = "center", fig.cap="log(Live Mass) as a function of log(Richness)."}
ggplot(comb, aes(x=log(rich), y = log(live_mass))) + geom_point()
```

We initially estimate and report $\beta$ in:
\begin{equation}
\ln(\text{Live Mass}_{pst}) = \alpha + \beta \ln(\text{Richness}_{pst}) + e_{pst}
(\#eq:eq1)
\end{equation}
where $p$ indexes plots, $s$ indexes sites, and $t$ indexes years. The unobserved error term is $e_{pst}$. We include a constant $\alpha$, but do not report estimates of it as it tells us little.

We report results below using all years of data first, and then report results using two individual years: 2012 and 2013. Here, as everywhere below, we [**cluster standard errors**](#clusterse) by plot to reflect serial correlation in errors terms within a plot across years (we do not assume that errors are iid). Note that when we use only a single year of data, this is equivalent to using heteroskedasticity-robust errors. 

```{r message=FALSE, warning=FALSE}
SimpleCorrAll <- feols(log(live_mass) ~ log(rich), comb, cluster = "newplotid") 

SimpleCorr2012 <- comb %>%
  filter(year==2012) %>%
  feols(log(live_mass) ~ log(rich), ., cluster = "newplotid") 

SimpleCorr2013 <- comb %>%
  filter(year==2013) %>%
  feols(log(live_mass) ~ log(rich), ., cluster = "newplotid") 

etable(SimpleCorrAll, SimpleCorr2012, SimpleCorr2013, 
          cluster = "newplotid", 
          drop = "Intercept", 
          subtitles = c("Data All Years", "Data in 2012", "Data in 2013"))  
```

As you can see, using all years of data gives a non-significant positive relationship between productivity and richness. In just the 2012 data, the coefficient is larger in magnitude, but still not significant. Finally, just using 2013 data, the coefficient switches signs and becomes significant. 

So... which one to believe? Well, probably none of these, because they likely do not identify the true causal effect of richness on productivity. Their variability highlights that these estimates, which rely on non-experimental [**cross-sectional**](#crosssectional) data, are likely contaminated by omitted variable bias.

When does $\hat{\beta}$ capture a causal relationship? When there are no unobservables that are correlated with richness that also influence productivity: $\mathbb{E}[e_{pst} \times \ln(\text{Richness}_{pst})]=0$ (i.e., $e_{pst}$ and $\ln(\text{Richness}_{pst})$ aren't correlated). In the above results, there's probably stuff in $e$ that is correlated with richness, like precipitation, disturbance, land-use history, soil characteristics, and other characteristics of sites and plots.

A [**Directed Acyclic Diagram**](#dag) (DAG) can help us see the challenges of omitted, and potentially confounding, variables more clearly. In the above analyses from equation \@ref(eq:eq1), $\beta$ is only identified if we assume that any variables that matter but that we omitted are uncorrelated with richness. 
One benefit of a DAG is that it makes transparent the assumptions on which one relies for making causal claims from observable data. A DAG therefore allows the researcher and the reader to better judge the credibility of the causal claims from a specific research design. Another way to view this benefit is that a causal graph helps identify the sources of variation in a causal variable and in its outcome, thereby emphasizing potential sources of bias that must be addressed in a research design and pointing to designs that can address these sources of [**statistical bias**](#bias) [@morganCounterfactualsCausalInference2014].

In our case, many variables that are correlated with biodiversity can also drive productivity (Fig. 1B -- main text), creating the possibility for rival explanations and biased estimates for estimated effects from observations. For example, climatic conditions, soil nutrients, evolutionary history, and historic contingency during community assembly are all related to both productivity and biodiversity [@Loreau1998;@fukamiCommunityAssemblyAlternative2011;@graceIntegrativeModellingReveals2016]. With a common driver of both variables that is not included in a model, two variables (i.e., biodiversity and an ecosystem function) may be correlated, even when there is no causal relationship between them. Similarly, no correlation between variables does not imply a lack of causation. Causal relationships can also be masked when examining correlations, due to an omitted variable (e.g., nitrogen addition), which positively affects productivity but negatively affects richness [@isbellNutrientEnrichmentBiodiversity2013]. Models that do not control for that common driver will consequently tend to give estimates that do not correspond to causal effects of biodiversity on productivity (or *vice versa*). 

<center>
<br />
<img src="https://imgur.com/nNFnoL2.png" width="45%" />
<br />
</center>   


Figure 1B (main text -- right panel) is known as a directed acyclic causal graph (DAG) and is a visualization of qualitative causal assumptions ([@pearl2009causality;  @pearl2011aspects;@fieberg2012understanding; @schoolmaster2013causal; @schoolmaster2020graphical; @Grace2020]). A DAG encodes knowledge and beliefs about how a system works. The graphical relations depicted in the DAG encode causal claims – not just representations of associations. A directed edge (e.g., R --> P) depicts a claim about the results of many hypothetical experiments, whereby if every other variable represented in the graph is held fixed, R and P will covary if R if manipulated, but not if P is manipulated (note, a DAG assumes that one can isolate the effect of R on P, but does not imply that P can never affect R; another DAG may represent the reverse direction, P --> R). 

<div style="background-color: #c5cae9">
TAKEAWAY:

Omitted variable bias is a pervasive feature in observational analysis, and the assumptions that permit identification of causal effects are unlikely to hold when using cross-sectional variation.
</div>

## Common Ecological Design - Multivariate Regression 

Of course, in the above correlations, we include plots in sites from across the world, implicitly comparing grasslands in warmer climates with those in cooler ones, or wetter with dryer, or Europe with the Americas. There are a lot of differences between these places! 
 
A common response to this problem is to try to measure these differences and include them in the model.  In the causal inference literature, this is known as [**“conditioning on observables”**](#conditioning) or Pearl’s [**back-door criteria**](#conditioning). Conditioning on observables is convenient but makes strong assumptions for causal inference, namely the [**“Selection on Observables” Assumption.**](#selectionobserv) Informally, this assumption implies that confounding variables that could introduce bias into a design are known and observable to the researcher. The bias they introduce into an estimator can be eliminated (controlled, blocked) by conditioning strategies, such as regression, matching, or stratification methods. To read more, see [@morganCounterfactualsCausalInference2014]. We can visualize this assumption by modifying our DAG, and using some examples in R:


<center>
<br />
<img src="https://i.imgur.com/s7w6Fhe.png" width="100%" />
<br />
</center>   

 
To explore the consequences of adding in covariates, we show the results of five models below. The first column repeats the first column from above. The second column adds in soil chemistry covariates, the third column instead adds weather covariates, and the fourth instead adds management variables plus habitat. The last columns adds in everything. For the purposes of this tutorial, we only show coefficient estimates for richness in the following table, even though the other terms are included in the model.

```{r message=FALSE, warning=FALSE}
SoilCovars <- feols(log(live_mass) ~ log(rich) +
                      pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +
                      pH + PercentSand + PercentSilt + PercentClay, 
                    comb, cluster = "newplotid") 

WeatherCovars <- feols(log(live_mass) ~ log(rich) +
                         elevation + TEMP_VAR_v2 + MIN_TEMP_v2 + MAX_TEMP_v2 + TEMP_WET_Q_v2 + TEMP_DRY_Q_v2 + TEMP_WARM_Q_v2 + 
                         TEMP_COLD_Q_v2, 
                       comb, cluster = "newplotid") 

MgmtCovars <- feols(log(live_mass) ~ log(rich) +
                      as.factor(habitat) + managed + burned + grazed + anthropogenic, 
                    comb, cluster = "newplotid") 

AllCovars <- feols(log(live_mass) ~ log(rich) +
                     pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +
                     pH + PercentSand + PercentSilt + PercentClay +
                     elevation + TEMP_VAR_v2 + MIN_TEMP_v2 + MAX_TEMP_v2 + TEMP_WET_Q_v2 + TEMP_DRY_Q_v2 + TEMP_WARM_Q_v2 +
                     TEMP_COLD_Q_v2 + as.factor(habitat) + managed + burned + grazed + anthropogenic, 
                   comb, cluster = "newplotid") 

etable(SimpleCorrAll, SoilCovars, WeatherCovars, MgmtCovars, AllCovars,
          cluster = "newplotid", 
          drop = "!rich", 
          subtitles = c("Data All Years", "+ Soil", "+ Weather", "+ Management", "+ All")) 
```

Estimates jump around depending on which covariates are used! This is likely a sign of some sort of omitted variables bias. Even though we consecutively explain more and more of the variation in the data, we are not necessarily any closer to a causal relationship.

There are a few other points to make about the above results that speak the practice of science. 

1.First, the number of observations changes based on which controls we use. Columns 2 and 5, where we only have 675 observations, might be on highly selected and not representative of the overall populations under study. A careful analysis could do any of a number of approaches to control for that, but far too often we just say ``This is what I have (all the) data for, so this what I estimate.'' It would be nice if there were a way to move forward even if we were unable to collect data on all the variables we wanted.

2.Second, and more perniciously, is specification hunting. What's to keep from only displaying results in columns 2 and 5 above, with no mention of the other results. P-hacking is something we should all be concerned about, but it's really easy to twiddle and play until one gets just the right set of results that agree with ones hypothesis.

3.Lastly, we assumed that all the covariates entered linearly and did not interact. What if what really matters is the interaction of nitrogen and precipitation? How do we capture that? We could include interactions and quadratics, or splines, but at some point, the number of covariates will exceed our sample size and nothing is identified.

<div style="background-color: #c5cae9">
TAKEAWAY: 

It is hard to assume the we observe and correctly control for all confounding variables when analyzing cross-sectional data
</div>

# Fixed Effects: Changing the Source of Variation

We now move on to the main course: Let's switch up where the **identification** comes from.

## Plot Fixed Effects

Let's ignore sites for a minute, and just think about the plots that lie in a single site. We're going to estimate the following model:
\begin{equation}
\ln(\text{Live Mass}_{pt}) = \beta \ln(\text{Richness}_{pt}) + \delta_p + \mu_t + e_{pt}
\end{equation}
where we've added the term $\delta_p$. This represents a vector of plot-specific fixed effect---a dummy variable for each plot. We also add time fixed effects ($\mu_t$, a dummy for each year) to control for the common differences to all plots in a year (in a site). We'll touch on that more later, but really, the *plot fixed effects are of greatest consequence*.

What does adding this vector of plot dummy variables do? Two big things. First, it controls for any and all time-invariant features of the plot, whether we observe them **or not**!!! To see this, imagine putting in a variable $x_p$ into the above equation linearly with the coefficient $\gamma$. We wouldn't actually be able to estimate $\gamma x_p$; it's already a component of $\delta_p$. Don't know what functional for you should use for $x_p$ or whether it should be interacted with another variable? That's fine, that's already included in $\delta_p$! We get a whole lot for the inclusion of this variable. Let's see our updated DAG: now we have removed confounding effects from plot-level attributes whether we can measure them or not! 
<center>
<br />
<img src="https://i.imgur.com/xJHFsrw.png" width="100%" />
<br />
</center>   

Second, and most importantly conceptually, is that we are no longer directly comparing different plots; we aren't using  cross-sectional variation any more. Instead, we are using variation in richness and productivity within the same plot *over time*. So, we're implicitly comparing a plot in year $t$ with this same plot in year $t+k$ for some $k$. Another way to see this is that we could write a very similar equation in differences (ignore the $\mu_t$ for a moment):
\begin{equation}
\left(\ln(\text{Live Mass}_{pt})-\ln(\text{Live Mass}_{pt-1}) \right)= \beta \left( \ln(\text{Richness}_{pt}) - \ln(\text{Richness}_{pt-1}) \right) + \left( e_{pt} - e_{pt-1}\right)
\end{equation}
Where did $\lambda_p$ go? Well, $\lambda_p-\lambda_p=0$, so we don't need it. (NB: We could also subtract the mean of each variable over time within each plot and arrive at a similar estimator. There are subtle differences between the two approaches that depend on the nature of the error terms $e$, but they draw on the same source of variation).

What do we have to assume for a causal interpretation? There are a couple of different assumptions we could choose; I think it's easiest to frame it like this: $\mathbb{E}[ (e_{pt} - e_{pt-1}) \times (\ln(\text{Richness}_{pt}) - \ln(\text{Richness}_{pt-1}))]=0$. That is, changes in richness are uncorrelated with *changes in* unobserved determinants of richness. Because time-invariant unobservable variables do not change, they are no longer a concern! Instead, we're concerned if movements in some unobserved factor could both be driving our outcome variable and be correlated with richness.


What's the cost? Well, there are a few to consider, but some really aren't much of a restriction:

1. We use to worry about computational issues. Instead of differencing, we could have including the additional fixed effects as regressors. Were this a large vector, computation could have become difficult. This is rarely a concern thanks to better computers and better techniques.

2. We need longitudinal (panel) data (or repeated cross sections in some special circumstances). This is why economists get so much use out of administrative data! This data is rarer in ecology, but with the growth in LTERs and other multi-year sites, this will be less of a constraint.

3. Our target of interest has to be time-varying. Any interesting time-invariant factors have been removed from the equation (literally).

Figures \@ref(fig:graphrawvary) and \@ref(fig:graphdeplotFE) illustrate graphically what the plot fixed effects do to the outcome variable (productivity). Figures \@ref(fig:graphrawvary) is just the raw data, and shows log(live mass) in four plots split between two sites (at the Sedgwick Reserve [sedg.us] and at the Sevilleta LTER [sevi.us]). Sedgwick has higher productivity on average. The productivity at these sites also appear to be following different trajectories through time (e.g., note the dip in productivity at Sevilleta in 2009). The plot fixed effects remove the average productivity in each site, as shown in Figure \@ref(fig:graphdeplotFE). They do not remove site-and-year specific sources of confounding variation (e.g., if a more extreme drought happened at Sevilleta than at Sedgwick in 2009 affecting both productivity and richness); we turn to eliminating site and year specific confounding variables below in \@ref(fig:graphdeplotsiteyearFE).

```{r message=FALSE, warning=FALSE, echo=FALSE}
comb$site <- comb$site_code
comb$plot = as.factor(comb$plot)

comb[,dm.changerich:=changerich-mean(changerich, na.rm=T), by=.(site,year)]
comb[,dm.changelive_mass:=changelive_mass-mean(changelive_mass, na.rm=T), by=.(site,year)]

comb[,`:=`(log.rich=log(rich), log.live_mass=log(live_mass))]
comb[order(year), change.log.rich := log(rich)-shift(log(rich)), by =.(plot, site_code)]
comb[order(year), change.log.live_mass := log(live_mass)-shift(log(live_mass)), by =.(plot, site_code)]
comb[,dm.change.log.rich:=change.log.rich-mean(change.log.rich, na.rm=T), by=.(site,year)]
comb[,dm.change.log.live_mass:=change.log.live_mass-mean(change.log.live_mass, na.rm=T), by=.(site,year)]

comb[,singledm.log.live_mass:=log.live_mass-mean(log.live_mass, na.rm=T), by=.(site, plot)]
comb[,doubledm.log.live_mass:=singledm.log.live_mass-mean(singledm.log.live_mass, na.rm=T), by=.(site, year)]

```


```{r graphrawvary, message=F, warning=F, echo=F, out.width = '60%', fig.align = "center", fig.cap="Raw variation in live mass at four plots across two sites."}
# plot raw variation - no fixed effects
ggplot(comb[(site=="sedg.us" & plot %in% c("1","17")) | (site=="sevi.us" & plot %in% c("8","12")),],
       aes(x=year, y=log.live_mass, group=plot, linetype=plot, color = site)) + 
  geom_line() +   scale_color_manual(values=c('#999999','#E69F00')) +
  ggtitle("Raw Variation in log(live biomass)") + 
  theme_bw() + 
  ylim(c(-1,7)) + labs(y = "log(Live biomass)") +  labs(x = "Year") + 
  theme(axis.title.y= element_text(size=14)) + theme(axis.title.x= element_text(size=14)) +
  theme(axis.text.y = element_text(size = 14)) 
```

```{r graphdeplotFE, message=F, warning=F, echo=F, out.width = '60%', fig.align = "center", fig.cap="Variation demaned by plot in live mass at four plots across two sites."}

ggplot(comb[site=="sedg.us" & plot %in% c("1","17") | (site=="sevi.us" & plot %in% c("8","12")), ],
       aes(x=year, y=singledm.log.live_mass, group=plot, linetype=plot, color = site)) + 
  geom_line() +    scale_color_manual(values=c('#999999','#E69F00')) +
  ggtitle("Variation in log(live biomass) after removing plot fixed effects") + 
  theme_bw() + 
  ylim(c(-5,7)) + labs(y = "log(Live biomass)") +  labs(x = "Year") + 
  theme(axis.title.y= element_text(size=14)) + theme(axis.title.x= element_text(size=14)) +
  theme(axis.text.y = element_text(size = 14)) 
```


To the statistical model: We're first going to estimate the following equation site-by-site on the five sites with the largest number of observations (in terms of the number plot-years we observe; see Table S1). 
\begin{equation}
\ln(\text{Live Mass}_{pt}) = \beta \ln(\text{Richness}_{pt}) + \delta_p + \mu_t + e_{pt}
\end{equation}
The year fixed effects $\mu_t$ control for *time-varying* factors (observed or unobserved) that affect all plots at the site under consideration. For example, suppose 2007 was a particularly damp and rainy year at the site; $\mu_t$ controls for the average impact of that across all plots. 
Because what happens at one site in a year is probably very different from what happens at a different site in the same year, we estimate these separately for each site. This will make the point estimates for each site less precise (especially because we're clustering by plot), but this is just for illustration's sake.

```{r message=FALSE, warning=FALSE}
PlotFE_1 <- comb %>%
  filter(site_code=="cdcr.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_2 <- comb %>%
  filter(site_code=="cdpt.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_3 <- comb %>%
  filter(site_code=="koffler.ca") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_4 <- comb %>%
  filter(site_code=="sedg.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_5 <- comb %>%
  filter(site_code=="sier.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

etable(SimpleCorrAll, PlotFE_1, PlotFE_2, PlotFE_3, PlotFE_4, PlotFE_5,
          cluster = "newplotid", 
          drop = "!rich", 
          subtitles = c("Data All Years","US - CDCR", "US - CDPT", "CA - Koffler", "US - SEDG", "US - SIER" )) 
```

We again show the bivariate correlation on all sites first (SimpleCorrAll), and then the estimate for each site. **Whoa!** Now we're getting some negative coefficients (though mostly insignificant due to smaller effective sample sizes). We're controlling for lots and lots of things that we couldn't control for before, either because we didn't think to include them or we couldn't collect data on them. The R-squared values confirm that this is the case; we're generally explaining much more of the data than before (but note: R-squared values are NOT important for causal interpretations generally). *Note that, with the plot fixed effects, we do not have much statistical power estimating sites individually.*


<div style="background-color: #c5cae9">
TAKEAWAY: 

Using unit fixed effects in panel data shifts the identifying variation from across units to within units over time.
</div>

## Bringing it all Together with Site-by-Year Fixed Effects

We now combine all sites together to give us more statistical power to detect effects. We do want to account for the fact that different sites experience different conditions in different years.
To do so in a flexible way, we include site-by-year fixed effects, $\mu_{st}$. 
\begin{equation}
\ln(\text{Live Mass}_{pst}) = \beta \ln(\text{Richness}_{pst}) + \delta_p + \delta_{st} +  e_{pst}
\end{equation}
These additional fixed effects control for all time-varying effects that impact the site as whole (i.e., that apply to all the plots equally). Thus, they capture the first order effects of weather, among other factors that could shift outcomes for the site as whole. This gives us sufficient power to conduct conservative inference on our estimated average treatment effect.


To get a sense for what these site-by-year effects do, first recall Figure \@ref(fig:graphdeplotFE). Plots that are in the same site seem to have similar movements in productivity over time, even after controlling for plot fixed effects. The site-by-year fixed effects remove the average of everything that happens across the site in the data in a year (e.g., a drought at a site). Figure \@ref(fig:graphdeplotsiteyearFE) removes this variation; see how the big drop in Sevilleta live mass in 2009 is much less Figure in \@ref(fig:graphdeplotsiteyearFE).


```{r message=FALSE, warning=FALSE, echo=FALSE}
comb[,doubledm.log.live_mass:=singledm.log.live_mass-mean(singledm.log.live_mass, na.rm=T), by=.(site, year)]
```

```{r graphdeplotsiteyearFE, message=F, warning=F, echo=F, out.width = '60%', fig.align = "center", fig.cap="Variation demaned by plot and site-by-year effects in live mass at four plots across two sites."}
sitebyyear = ggplot(comb[site=="sedg.us" & plot %in% c("1","17") | (site=="sevi.us" & plot %in% c("8","12")),],
       aes(x=year, y=doubledm.log.live_mass, group=plot, linetype=plot, color = site)) + 
  geom_line() +   scale_color_manual(values=c('#999999','#E69F00')) +
  ggtitle("Variation in log(live biomass) after removing plot fixed and site by year effects") +
  theme_bw() +  
  ylim(c(-5,7)) 

sitebyyear +
  labs(y = "log(Live biomass)") +  labs(x = "Year") + 
   theme(axis.title.y= element_text(size=14)) + theme(axis.title.x= element_text(size=14)) +
  theme(axis.text.y = element_text(size = 14)) 
```



To provide confidence that the results are robust, we will also include a couple of time-varying controls, evenness and lagged richness. NB: To make sure we don't drop locations with values of zero evenness, we use the inverse hyperbolic sine instead of the natural log. Note that we don't need to worry about that for productivity or richness because they never take a zero value.
```{r message=FALSE, warning=FALSE}

ihs <- function(x) {
  y <- log(x+sqrt(x^2 + 1))
}


MainMod_Rich     <- feols(log(live_mass) ~ log(rich)  | newplotid + site.by.yeardummy, comb) 
MainMod_RichEven <- feols(log(live_mass) ~ log(rich) + ihs(even) | newplotid + site.by.yeardummy, comb) 
MainMod_RichLag  <- feols(log(live_mass) ~ log(rich) + log(laggedrich) | newplotid + site.by.yeardummy, comb) 
MainMod_RichEvenLag <- feols(log(live_mass) ~ log(rich) + log(laggedrich) + ihs(even) | newplotid + site.by.yeardummy, comb)

etable(MainMod_Rich, MainMod_RichEven, MainMod_RichLag, MainMod_RichEvenLag,
          cluster = "newplotid")

```

As you can see, estimate on log richness are relatively stable across different specifications. Of special note: the coefficient on lagged richness (richness from the year before) is small and insignificant, given us confidence that our results reflect *contemporaneous* movement in richness, and not some factor that is also correlated with last year's richness.

<div style="background-color: #c5cae9">
TAKEAWAY: 

Fixed effects can alter the research design and control for a wide variety of potentially confounding factors!
</div>

Our updated DAG, including both plot and site-by-year fixed effects, show that we can control more flexibly for a broader set of confounding variables in space and time -- critically, whether they are measured or not! 
<center>
<br />
<img src="https://i.imgur.com/pf8QmGi.png" width="100%" />
<br />
</center>   

# Graphical Depictions of Fixed Effects

Using simple plots of the relationships between richness and productivity (as log of richness and log of live mass), we can see the relationships shift from positive to negative as we add in fixed effects. 

Figure \@ref(fig:RawBivariate) just shows the raw bivariate correlation, and is somewhat positive. Notice the range of variation across productivity and richness.

```{r RawBivariate, message=F, warning=F, echo=F, out.width = '60%', fig.align = "center", fig.cap="The bivariate relationship with no controls."}
# Cross-sectional analog - ignoring fixed effects and any other covariates
comb[,`:=`(log.rich=log(rich), log.live_mass=log(live_mass))]
ggplot(comb[!is.na(log.rich) & !is.na(log.live_mass),], 
       aes(x=log.rich, 
           y=log.live_mass)) + 
  geom_smooth(method="lm", se=T) + labs(y = "log(Live biomass)") + labs(x = "log(Richness)") + 
  theme_bw() +
  geom_point()
```

Figure \@ref(fig:plotFixedEffects) shows the relationship conditional on plot fixed effects. Note that this collapses the range of variation substantially. Recall that the plot fixed effects remove factors that are time-invariant and plot-specific. However, this graph still reflects the variation in sites across years.

```{r plotFixedEffects, message=F, warning=F, echo=F, out.width = '60%', fig.align = "center", fig.cap="Controlling for only plot-level attributes that do not change through time"}
# Plot FE only
# We'll also do (double) demeaning of logged values to mimic 
# what's done in log-log model
comb[order(year), change.log.rich := log(rich)-shift(log(rich)), by =.(plot, site_code)]
comb[order(year), change.log.live_mass := log(live_mass)-shift(log(live_mass)), by =.(plot, site_code)]

ggplot(comb[!is.na(change.log.rich) & !is.na(change.log.live_mass),], 
       aes(x=change.log.rich, 
           y=change.log.live_mass)) + labs(y = "log(Live biomass)") + labs(x = "log(Richness)") + 
  geom_smooth(method="lm", se=F) + 
  theme_bw() +
  geom_point()
```

Figure \@ref(fig:siteyrplotFixedEffects) continues to control for plot fixed effects, but also removes site-by-year variation via site-by-year fixed effects. This shifts the variation negative as factors that are common to sites within years no longer confound the relationship.

```{r siteyrplotFixedEffects, message=F, warning=F, echo=F, out.width = '60%', fig.align = "center", fig.cap="Controlling for plot attributes and attributes of sites that change through time"}
comb[,dm.changerich:=changerich-mean(changerich, na.rm=T), by=.(site,year)]
comb[,dm.changelive_mass:=changelive_mass-mean(changelive_mass, na.rm=T), by=.(site,year)]
comb[,dm.change.log.rich:=change.log.rich-mean(change.log.rich, na.rm=T), by=.(site,year)]
comb[,dm.change.log.live_mass:=change.log.live_mass-mean(change.log.live_mass, na.rm=T), by=.(site,year)]

# Panel analog (plot FE and site-year effects)
ggplot(comb[!is.na(dm.change.log.rich) & !is.na(dm.change.log.live_mass),], 
       aes(x=dm.change.log.rich, 
           y=dm.change.log.live_mass)) + labs(y = "log(Live biomass)") + labs(x = "log(Richness)") + 
  geom_smooth(method="lm", se=F) +
  theme_bw() +
  geom_point()

```


# Random Effects Don't Usually Cut It... 

Researchers sometimes turn to random effects models to attempt to deal with confounding variables or *unobserved heterogeneity*. While random effects models have a number of useful properties (reviewed in @bell2019fixed), they **do not solve endogeneity problems** on their own (see [@wooldridge2010econometric;@wooldridge2015introductory;@larsen2019causal]). Any variable that is omitted from a random effects model is implicitly assumed to either have no effect on productivity or to be uncorrelated with explanatory variables. So, random effects on their own don't really buy us anything more than conditioning on observables in terms of establishing causality. 

To see this, consider again our simple model:
\begin{equation}
\ln(\text{Live Mass}_{pt}) = \beta \ln(\text{Richness}_{pt}) + \delta_p + \mu_t + e_{pt}
\end{equation}
The random effects assumption is that $\ln(\text{Richness}_{pt})$ and $\delta_p$ are uncorrelated. This is a strong assumption; it says that no tunobservables (even time-invariant ones) are correlated with richness! So, random effects with no controls assume average rainfall or latitude don't matter for richness. Of course, one could add controls, but then we're back to the question of do we include the right measures of the controls in the right functional form, etc.

By contrast, recall that the fixed effects assumption allows for arbitrary correlation between richness and any time-invariant variables, whether observed or not. So, should you include a fifth-degree polynomial in latitude. Nope, just include the fixed effect.


Check out how the results below change (or not) in response to fixed effects (references for more details on the mathematics behind this are listed later on). First, consider the two linear models (without random effects) with different sets of soil variables:
```{r message=FALSE, warning=FALSE}

## Linear Model with Soil Covariates
SoilCovars <- feols(log(live_mass) ~ log(rich) +
                      pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B, 
                    comb, cluster = "newplotid") 

## Linear Model with More Soil Covariates
SoilCovars_More <- feols(log(live_mass) ~ log(rich) +
                      pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +
                      pH + PercentSand + PercentSilt + PercentClay, 
                    comb, cluster = "newplotid") 

etable(SoilCovars, SoilCovars_More,
          cluster = "newplotid", 
          drop = "!rich", 
          subtitles = c("Some soil covariates","More soil covariates")) 

```

See how the covariate of interest jumps around. Again, that's a reminder that there are likely omitted variables that are pretty correlated with our variable of interest.

So, that's our baseline. Now let's see what happens with random effects! 

```{r message=FALSE, warning=FALSE}

## First, characteristics of soil influence both productivity and richness. We use covariates that characterize several aspects of the soil fertility and nutrients. We include plot and site random effects.
MixedMod_Rich_soil <- lmer(log(live_mass) ~ log(rich) + 
                             pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +   pH + PercentSand + PercentSilt + PercentClay +    (1|newplotid) +   (1|site_code), comb, REML = F)
summary(MixedMod_Rich_soil)


## We now bring in management variables, and retain the plot and site random effects.
MixedMod_Rich2 <- lmer(log(live_mass) ~ log(rich) + 
                         managed + burned + grazed + anthropogenic + 
                         pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +   pH + PercentSand + PercentSilt + PercentClay +    (1|newplotid) +                             (1|site_code), comb, REML = F)
summary(MixedMod_Rich2 )


## we also can bring in controls for country, habitat, and year, again retaining the plot and site random effects. 
MixedMod_Rich <- lmer(log(live_mass) ~ log(rich) + as.factor(country) + as.factor(habitat) + as.factor(year) + 
                        elevation + managed + burned + grazed + anthropogenic + 
                        TEMP_VAR_v2 + MIN_TEMP_v2 + MAX_TEMP_v2 + TEMP_WET_Q_v2 + TEMP_DRY_Q_v2 + TEMP_WARM_Q_v2 +                            TEMP_COLD_Q_v2 +   pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +            ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +   pH + PercentSand + PercentSilt + PercentClay +    (1|newplotid) +                             (1|site_code), comb, REML = F)
summary(MixedMod_Rich )

```

Across these models, note that the coefficient on log richness does not really change, and is not very different from the linear model above that include additional covariates. This is because random effects are not really controlling for factors that both correlate with richness and with productivity.

Why ever use random effects? Well, when the assumption of no correlation between the explanatory variable and the random effect holds, random effects estimates are more efficient. But generally, bias is the first order concern with observational data.


# Accounting for other sources of confounding variables
A hallmark of modern approaches to causal inference is to probe the robustness of results to potential violations in the assumptions used to infer causality from correlation.
Using four approaches, we use different assumptions than made in our Main Design (the two-way fixed effects estimator -- in Figure 2A) and assess how the conclusions change (see SM). Causal inference in each approach requires causal assumptions, but each approach makes different assumptions. In other words, each approach can detect hidden biases in our design (i.e., threats to internal validity) under different conditions. Our causal interpretations in the paper are strengthened by the robustness of our inferences to changes in the causal assumptions. In other words, it’s not hard to knock one of the analyses as having limitations, but it’s harder to come up with a story that explains the pattern we observe across all of the analyses (including the complementary analyses about species richness as a heterogeneous treatment in Figs 4 and 5). The results are shown in Figure 3 of the main text and the analyses are described in detail in the SM. 

<div style="background-color: #c5cae9">
TAKEAWAY: The best way to view all of the analyses described in Figure 3 is that each analysis uses different causal assumptions yet comes to the same conclusion. That pattern is the source of our paper’s strength of evidence: the results of each individual analysis could be explained by a different rival explanation, but it is hard to come up with a coherent set of rival explanations that could explain them all. And, if so, the analyses and rival explanation point to a clear direction for future studies to examine.
</div>

We provide some examples of the types of confounding variables addressed by these additional analysis designs. These examples are illustrative, not intended to be exhaustive: 

**Dynamic Panel model addresses potential biases** from, for example,:
*	Soil fertility or plant-soil feedbacks
* Dead standing material/litter influencing (especially annual) recruitment in the following growing season
* Prior plot-specific disturbances or other shocks that are at the plot level
* Dynamic effects of productivity on richness (across years)
* Maternal effects
* etc. 

**Sensitivity analysis and Instrumental Variables (IV) Design address potential biases in two different ways** from, for example,

* Micro-climate at the plot level that changes through time
* Insect community composition, pollination communities, herbivory rates
* Measurement error
* Disturbances that are plot specific (e.g., gophers)

**IV and Mechanism blocking designs address potential biases in two different ways** from so-called "reverse causality" 

* The effect of within-season productivity on richness (and related pathways such a plant height, shading) 

The assumptions for each design are laid out in simple form in Figure 3 in the main text (and see below), and at length in the Supplemental Materials (also see Figure S4, S5, S6, S7, and S8 for visuals).

<center>
<br />
<img src="https://i.imgur.com/Ho4yWS6.png" width="100%" />
<br />
</center>   


# Glossary

<a name="bias">[Bias and Hidden Bias](#crosssectinalback)</a>

: Bias is a property of an estimator of a causal effect: it captures the difference between the estimator's expected value and the true value of the causal effect being estimated [@wooldridge2015introductory]. The phrase "hidden bias" (also called "unobserved heterogeneity") is often used to describe the potential sources of bias in a study design (e.g., an omitted third variable that affects both biodiversity and productivity). Hidden bias is thus a rival explanation for detecting or failing to detect a correlation between a purported causal variable and its outcome using observable data [@ferraro2014advances].  The goal of causal analysis is to choose data and a design so that an actual causal effect would be visibly different from the most plausible hidden biases. Note: sampling variability ("noise") is different from hidden bias; sampling variability is not a source of bias. Reviewed in  [@larsen2019causal] for ecologists.

<a name="clusterse">[Cluster standard errors](#clusterseback)</a>

: Standard errors that are robust to arbitrary correlation and heteroskedasticity within groups ("cluster"). A standard tool for inference with panel data. See [@wooldridge2010econometric] and [@Cameron2015].

<a name="conditioning">[Conditioning on Observables](#selectionobservback)</a>

: Typically used as a synonym for "controlling" for, i.e., a model that conditions on set of observables typically means that it has included those observables linearly as control variables.


<a name="confounders">Confounding Variables (or "confounders")</a>

: In this study, we use the term "confounding variable" to describe variables that are systematically correlated with the causal variable (e.g., biodiversity) and the outcome variable (e.g., productivity), and thus can mask or mimic a causal effect. Confounding variables are a potential source of bias in a **non-experimental** study design.

<a name="crosssectional">[Cross-sectional Data](#crosssectinalback)</a>

: Data without repeated measures taken from a sample. Instead, one measure is taken from each unit of analysis (e.g., plot). For example, analyses of the effect of biodiversity on productivity in cross-sectional data have only one observation per plot. It is is hard to assume the we observe and correctly control for all confounding variables when analyzing cross-sectional data. 

<a name="dag">[Direct Acyclic Graph](#dagback)</a>

: Generally, a directed graph (a network with connections in which the direction of flow matters) with no directed cycles (no repeating loops). When working with observational data, a tool used to understand potential confoudning pathways, see e.g., [this tutorial](https://imai.fas.harvard.edu/teaching/files/DAG.pdf).

<a name="endogeneity">[Endogeniety](#endogeneityback)</a>

: Broadly, situations in which the variable of interest is correlated with the error term. The goal of causal analysis using observational data is typically to reduce or remove endogeneity. See [@wooldridge2015introductory]; reviewed in [@larsen2019causal] and [@kendall2015statistical] for ecologists, also
[this video](https://www.youtube.com/watch?v=_sRlvKws7F8)

<a name="errors">Errors versus Residuals</a>:

: The error term is part of the *true* data generating process. In contrast, residuals are the difference between the regression line and the observed data points. Residuals cannot be used to assess potential bias in an estimation procedure. 

<a name="identification">Identification</a>

: Formally, a parameter is point identified if it can be uniquely determined from data (usually via a research design). Commonly used to denote whether an estimator of a parameter converges in probability to the value the researcher is seeking; e.g., "Under these three assumptions, $\beta$ is identified" (meaning it reflects the the value of interest, like a causal effect). See [@larsen2019causal] for a review for ecologists 

<a name="instrumental">Instrumental Variable</a>

: This term is defined in in Figure 1B as variable Z, a variable that affects the treatment variable (in our study, “species richness”) but has no direct effect on the outcome variable (in our study, “above-ground biomass”) except through its effect on the treatment. In a randomized experiment, the instrumental variable is the randomization procedure. To read more, see [@imbens2014instrumental;@kendall2015statistical] and our SM. 

<a name="panel">Panel Data</a>

: Panel data are longitudinal data comprising repeated measures taken from a sample of cases (e.g., plots, sites, regions). Such data are also sometimes referred to as longitudinal multilevel data. See our SM section S3 for more detail on this panel data. For an excellent introduction to approaches using panel data, see [@angrist2008mostly].

<a name="rivalexplanations">[Rival Explanations](#rivalexplanationsback)</a>

: Alternative narratives that can explain estimated relationships but that do not violate identification. 

<a name = "selectionobserv">[Selection on Observables" Assumption](#selectionobservback)</a>

: Informally, this assumption implies that confounding variables that could introduce bias into a design are known and observable to the researcher. The bias they introduce into an estimator can thus be eliminated (controlled, blocked) by conditioning strategies, such as regression, matching or stratification methods. To read more, see [@morganCounterfactualsCausalInference2014].







# References

<div id="refs"></div>


