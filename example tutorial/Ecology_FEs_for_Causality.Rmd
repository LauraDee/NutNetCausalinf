---
title: 'Panel Data and Fixed Effects Methods for Ecology'
author: "Online tutorial for the analyses run in: Dee et al."
date: 'Last updated: `r Sys.Date()`'
output:
  bookdown::html_document2:
    smart: no
    df_print: kable
    theme: flatly
    toc: true
    toc_float: true
bibliography: [FE.bib]
biblio-style: "apalike"
link-citations: true
---
<!-- ## internal notes for how to use markdown -->

<!-- points 1 and 2 are quite easy to deal using bookdown instead of markdown. To do so you juste have to replace the "output: html_document"  with "output: bookdown::html_document2" in the yaml section.  -->

<!-- -Then, you can make references to sections using \@ref(name-of-section) where name-of-section is the section title in downcase letters and with spaces replaced by ‘-‘.  -->
<!-- -You can make references to figures using \@ref(fig:block) where block is the name of the r block that has produces the figure. Table will also work using \@ref(table:tablename). -->
<!-- - For equations, you have to label the equations using (\#eqname) inside the \begin{equation} \end{equation} block and then use  \@ref(eq:eqname) in the text -->
<!-- - For colours, I don’t know an easy solution but you can use html code directly:  -->
<!-- <div style="color: red; »> -->
<!--         This is an R Markdown document.  -->
<!-- </div> -->
<!-- will print the sentence in red.  -->

# Setup and Load Data

The data used in this tutorial comes from the [Nutrient Network](https://nutnet.org/). It has been cleaned and processed and is ready to use. The data correspond to what we use in the paper for the main analysis, and consists of control plots from 43 NutNet sites. Each site includes one or more control plots that we use. We only use plots for which we have at least 5 years of data.

We'll primarily use the *fixest* package for analysis; the other packages (*tidyverse*, *data.table*, *lme4*) aid data wrangling and comparing research designs.
```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(fixest)
library(lme4)  # Need at least version 1.1-26

cdir <- getwd()
comb <- fread(paste(cdir,"/cleaned_comb_data.csv",sep=""),na.strings='NA')
```

The *comb* dataset contains a wide number of variables; we'll mainly be using the variables *live_mass* and *rich*. Also important are the *site_code*, *plot*, and *year* variables, which we use to create fixed effects (site-by-year fixed were created with `"r comb[, site.by.yeardummy := paste(site_code, year, sep = "_")]"`).


# Standard Approaches

For causal inference, we need to answer, *how much does a change in $X$ lead to a change in $Y$*. Causal inference involves ruling out **rival explanations** for an estimated relationship. This aim and requirement differs from other research tasks (e.g., predicting where total productivity will be the highest, which can be done without knowing the true underlying causes of productivity). Thus, the criteria for evaluating causal inference differ from other task. For example, prediction or forecasting of rely on model fit measures, such as R-squared values or mean squared error [see @ferraroCausalInferenceCoupled2018]. 

We evaluate causal inference by assessing the credibility and validity of the assumptions made by the research design for each dataset, system, and question [reviewed in @ferraroCausalInferenceCoupled2018], as we will illustrate next.  Being explicit about these assumptions and evaluating how reasonable they are is important for causal inference. 


## Simple correlations in single years

Let's begin by looking at simple correlations. We will examine both the overall correlation and correlations within a single year (i.e., using cross-sectional variation). We proceed with a linear regression framework \@ref(eq:eq1), using the log of productivity (measured as live aboveground biomass) as the outcome and the log species richness as the explanatory variable.  We've found that a log-log specification captures the nature of the relationship in our data well (see Figure \@ref(fig:graphbiomasssp) below and the paper for details).

```{r graphbiomasssp, echo = F, fig.cap="log(Live Mass) as a function of log(Richness)."}
ggplot(comb, aes(x=log(rich), y = log(live_mass))) + geom_point()
```

We initially estimate and report $\beta$ in:
\begin{equation}
\ln(\text{Live Mass}_{pst}) = \alpha + \beta \ln(\text{Richness}_{pst}) + e_{pst}
(\#eq:eq1)
\end{equation}
where $p$ indexes plots, $s$ indexes sites, and $t$ indexes years. The unobserved error term is $e_{pst}$. We include a constant $\alpha$, but do not report estimates of it as it tells us little.

We report results below using all years of data first, and then report results using two individual years: 2012 and 2013. Here, as everywhere below, we cluster standard errors by plot to reflect serial correlation in errors terms within a plot across years (we do not assume that errors are iid). Note that when we use only a single year of data, this is equivalent to using heteroskedasticity-robust errors.

```{r message=FALSE, warning=FALSE}
SimpleCorrAll <- feols(log(live_mass) ~ log(rich), comb, cluster = "newplotid") 

SimpleCorr2012 <- comb %>%
  filter(year==2012) %>%
  feols(log(live_mass) ~ log(rich), ., cluster = "newplotid") 

SimpleCorr2013 <- comb %>%
  filter(year==2013) %>%
  feols(log(live_mass) ~ log(rich), ., cluster = "newplotid") 

etable(SimpleCorrAll, SimpleCorr2012, SimpleCorr2013, 
          cluster = "newplotid", 
          drop = "Intercept", 
          subtitles = c("Data All Years", "Data in 2012", "Data in 2013"))  
```

As you can see, using all years of data gives a non-significant positive relationship between productivity and richness. In just the 2012 data, the coefficient is larger in magnitude, but still not significant. Finally, just using 2013 data, the coefficient switches signs and becomes significant. 

So... which one to believe? Well, probably none of these, because they likely do not identify the true causal effect of richness on productivity. Their variability highlights that these estimates, which rely on non-experimental **cross-sectional** data, are likely contaminated by omitted variable bias.

When does $\hat{\beta}$ capture a causal relationship? When there are no unobservables that are correlated with richness that also influence productivity: $\mathbb{E}[e_{pst} \times \ln(\text{Richness}_{pst})]=0$ (i.e., $e_{pst}$ and $\ln(\text{Richness}_{pst})$ aren't correlated). In the above results, there's probably stuff in $e$ that is correlated with richness, like precipitation, disturbance, land-use history, soil characteristics, and other characteristics of sites and plots.

A **Directed Acyclic Diagram** (DAG) can help us see the challenges of omitted, and potentially confounding, variables more clearly. In the above analyses from equation \@ref(eq:eq1), $\beta$ is only identified if we assume that any variables that matter but that we omitted are uncorrelated with richness. 
One benefit of a DAG is that it makes transparent the assumptions on which one relies for making causal claims from observable data. A DAG therefore allows the researcher and the reader to better judge the credibility of the causal claims from a specific research design. Another way to view this benefit is that a causal graph helps identify the sources of variation in a causal variable and in its outcome, thereby emphasizing potential sources of bias that must be addressed in a research design and pointing to designs that can address these sources of **statistical bias** [@morganCounterfactualsCausalInference2014].

In our case, many variables that are correlated with biodiversity can also drive productivity (Fig. 1B -- main text), creating the possibility for rival explanations and biased estimates for estimated effects from observations. For example, climatic conditions, soil nutrients, evolutionary history, and historic contingency during community assembly are all related to both productivity and biodiversity (Loreau 1998; Fukami & Nakajima 2011; Grace et al. 2016a). With a common driver of both variables that is not included in a model, two variables (i.e., biodiversity and an ecosystem function) may be correlated, even when there is no causal relationship between them. Similarly, no correlation between variables does not imply a lack of causation. Causal relationships can also be masked when examining correlations, due to an omitted variable (e.g., nitrogen addition), which positively affects productivity but negatively affects richness (Isbell et al. 2013). Models that do not control for that common driver will consequently tend to give estimates that do not correspond to causal effects of biodiversity on productivity (or vice versa). 

<center>
<br />
<img src="https://imgur.com/nNFnoL2.png" width="65%" />
<br />
</center>   

Figure 1B (main text -- right panel) is known as a directed acyclic causal graph (DAG) and is a visualization of qualitative causal assumptions (Pearl 2009, 2011; Fieberg & Ditmer 2012; Schoolmaster et al. 2013, 2020). A DAG encodes knowledge and beliefs about how a system works. The graphical relations depicted in the DAG encode causal claims – not just representations of associations. A directed edge (e.g., R --> P) depicts a claim about the results of many hypothetical experiments, whereby if every other variable represented in the graph is held fixed, R and P will covary if R if manipulated, but not if P is manipulated (note, a DAG assumes that one can isolate the effect of R on P, but does not imply that P can never affect R; another DAG may represent the reverse direction, P --> R). 

**TAKEAWAY: Omitted variable bias is a pervasive feature in observational analysis, and the assumptions that permit identification of causal effects are unlikely to hold when using cross-sectional variation.**

## Common Ecological Design - Multivariate Regression 

Of course, in the above correlations, we include plots in sites from across the world, implicitly comparing grasslands in warmer climates with those in cooler ones, or wetter with dryer, or Europe with the Americas. There are a lot of differences between these places! 
 
A common response is to try to measure these differences and include them in the model.  In the causal inference literature, thisis known as **“conditioning on observables”** or Pearl’s **back-door criteria**. Conditioning on observables is convenient but makes strong assumptions for causal inference, namely the **“Selection on Observables” Assumption.** Informally, this assumption implies that confounding variables that could introduce bias into a design are known and observable to the researcher. The bias they introduce into an estimator can be eliminated (controlled, blocked) by conditioning strategies, such as regression, matching, or stratification methods. To read more, see (REF 1). We can visualize this assumption by modifying our DAG, and using some examples in R:

**INSERT DAG WITH THIS ASSUMPTION**

To explore the consequences of adding in covariates, we show the results of five models below. The first column repeats the first column from above. The second column adds in soil chemistry covariates, the third column instead adds weather covariates, and the fourth instead adds management variables plus habitat. The last columns adds in everything. We only show coefficient estimates for richness, even though the other terms are included in the model.

```{r message=FALSE, warning=FALSE}
SoilCovars <- feols(log(live_mass) ~ log(rich) +
                      pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +
                      pH + PercentSand + PercentSilt + PercentClay, 
                    comb, cluster = "newplotid") 

WeatherCovars <- feols(log(live_mass) ~ log(rich) +
                         elevation + TEMP_VAR_v2 + MIN_TEMP_v2 + MAX_TEMP_v2 + TEMP_WET_Q_v2 + TEMP_DRY_Q_v2 + TEMP_WARM_Q_v2 + 
                         TEMP_COLD_Q_v2, 
                       comb, cluster = "newplotid") 

MgmtCovars <- feols(log(live_mass) ~ log(rich) +
                      as.factor(habitat) + managed + burned + grazed + anthropogenic, 
                    comb, cluster = "newplotid") 

AllCovars <- feols(log(live_mass) ~ log(rich) +
                     pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +
                     pH + PercentSand + PercentSilt + PercentClay +
                     elevation + TEMP_VAR_v2 + MIN_TEMP_v2 + MAX_TEMP_v2 + TEMP_WET_Q_v2 + TEMP_DRY_Q_v2 + TEMP_WARM_Q_v2 +
                     TEMP_COLD_Q_v2 + as.factor(habitat) + managed + burned + grazed + anthropogenic, 
                   comb, cluster = "newplotid") 

etable(SimpleCorrAll, SoilCovars, WeatherCovars, MgmtCovars, AllCovars,
          cluster = "newplotid", 
          drop = "!rich", 
          subtitles = c("Data All Years", "+ Soil", "+ Weather", "+ Management", "+ All")) 
```

Estimates jump around depending on which covariates are used! This is likely a sign of some sort of omitted variables bias. Even though we consecutively explain more and more of the variation in the data, we are not necessarily any closer to a causal relationship.

There are a few other points to make about the above results that speak the practice of science. 
1.First, the number of observations changes based on which controls we use. Columns 2 and 5 might be on highly selected sample, and not representative of the overall populations under study. A careful analysis could do any of a number of approaches to control for that, but far too often we just say ``This is what I have (all the) data for, so this what I estimate.'' It would be nice if there were a way to move forward even if we were unable to collect data on all the variables we wanted.
2.Second, and more perniciously, is specification hunting. What's to keep from only displaying results in columns 2 and 5 above, with no mention of the other results. P-hacking is something we should all be concerned about, but it's really easy to twiddle and play until one gets just the right set of results that agree with ones hypothesis.
3.Lastly, we assumed that all the covariates entered linearly and did not interact. What if what really matters is the interaction of nitrogen and precipitation? How do we capture that? We could include interactions and quadratics, or splines, but at some point, the number of covariates will exceed our sample size and nothing is identified.

**TAKEAWAY: It is hard to assume the we observe and correctly control for all confounding variables when analyzing cross-sectional data**

# Fixed Effects: Changing the Source of Variation

We now move on to the main course: Let's switch up where the identification comes from.

## Plot Fixed Effects

Let's ignore sites for a minute, and just think about the plots that lie in a single site. We're going to estimate the following model:
\begin{equation}
\ln(\text{Live Mass}_{pt}) = \beta \ln(\text{Richness}_{pt}) + \lambda_p + e_{pt}
\end{equation}
where we've added the term $\lambda_p$. This represents a vector of plot-specific fixed effect---a dummy variable for each plot. We'll also add time fixed effects (a dummy for each year) to control for the common differences to all plots in a year (in a site), and we'll touch on that later, but really, the plot fixed effects are of greatest consequence.

What does adding this vector of plot dummy variables do? Two big things. First, it controls for any and all time-invariant features of the plot, whether we observe them OR NOT!!! To see this, imagine putting in a variable $x_p$ into the above equation linearly with the coefficient $\gamma$. We wouldn't actually be able to estimate $\gamma x_p$; it's already a component of $\lambda_p$. Don't know what functional for you should use for $x_p$ or whether it should be interacted with another variable? That's fine, that's already included in $\lambda_p$! We get a whole lot for the inclusion of this variable. 

Second, and most importantly conceptually, is that we are no longer directly comparing different plots; we aren't using  cross-sectional variation any more. Instead, we are using variation in richness and productivity within the same plot *over time*. So, we're implicitly comparing a plot in year $t$ with this same plot in year $t+k$ for some $k$. Another way to see this is that we could write a very similar equation in differences:
\begin{equation}
(\ln(\text{Live Mass}_{pt})-\ln(\text{Live Mass}_{pt-1}) = \beta ( \ln(\text{Richness}_{pt}) - \ln(\text{Richness}_{pt-1})) + (e_{pt} - e_{pt-1})
\end{equation}
Where did $\lambda_p$ go? Well, $\lambda_p-\lambda_p=0$, so we don't need it. (NB: We could also subtract the mean of each variable over time within each plot and arrive at a similar estimator. There are subtle differences between the two approaches that depend on the nature of the error terms $e$, but they draw on the same source of variation).

What do we have to assume for a causal interpretation? There are a couple of different assumptions we could choose; I think it's easiest to frame it like this: $\mathbb{E}[ (e_{pst} - e_{pst-1}) \times (\ln(\text{Richness}_{pst}) - \ln(\text{Richness}_{pst-1}))]=0$. That is, changes in richness are uncorrelated with *changes in* unobserved determinants of richness. Because time-invariant unobservables do not change, they are no longer a concern! Instead, we're concerned if movements in some unobserved factor could both be driving our outcome variable and be correlated with richness.



What's the cost? Well, there are a few to consider, but some really aren't much of a restriction: 
1. We use to worry about computational issues. Instead of differencing, we could have including the additional fixed effects as regressors. Were this a large vector, computation could have become difficult. This is rarely a concern thanks to better computers and better techniques.
2. We need longitudinal (panel) data (or repeated cross sections in some special circumstances). This is why economists get so much use out of administrative data! This data is rarer in ecology, but with the growth in LTERs and other multi-year sites, this is less of a constraint.
3. Our target of interest has to be time-varying. Any interesting time-invariant factors have been removed from the equation (literally).

PUT IN FIGURE: RAW VARIATION AND PLOT FIXED EFFECTS


We're first going to estimate the following equation site-by-site on the five largest sites (in terms of the number plot-years we observe). 
\begin{equation}
\ln(\text{Live Mass}_{pt}) = \beta \ln(\text{Richness}_{pt}) + \lambda_p + \delta_t + e_{pt}
\end{equation}
The year fixed effects $\delta_t$ control for *time-varying* factors (observed or unobserved) that affect all plots at the site under consideration. For example, suppose 2007 was a particularly damp and rainy year at the site; $\delta_t$ controls for the average impact of that across all plots. 
Because what happens at one site in a year is probably very different from what happens at a different site in the same year, we estimate these separately for each site. This will make the point estimates for each site less precise (especially because we're clustering by plot), but this is just for illustration's sake.

```{r message=FALSE, warning=FALSE}
PlotFE_1 <- comb %>%
  filter(site_code=="cdcr.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_2 <- comb %>%
  filter(site_code=="cdpt.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_3 <- comb %>%
  filter(site_code=="koffler.ca") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_4 <- comb %>%
  filter(site_code=="sedg.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

PlotFE_5 <- comb %>%
  filter(site_code=="sier.us") %>%
  feols(log(live_mass) ~ log(rich) | newplotid + year, ., cluster = "newplotid")

etable(SimpleCorrAll, PlotFE_1, PlotFE_2, PlotFE_3, PlotFE_4, PlotFE_5,
          cluster = "newplotid", 
          drop = "!rich", 
          subtitles = c("Data All Years","US - CDCR", "US - CDPT", "CA - Koffler", "US - SEDG", "US - SIER" )) 
```

We again plot the bivariate correlation first, and then the estimate for each site. **Whoa!** Now we're getting some negative coefficients (though mostly insignificant due to smaller effective sample sizes). We're controlling for lots and lots of things that we couldn't control for before, either because we didn't think to include them or we couldn't collect data on them. The R-squared values confirm that this is the case; we're generally explaining much more of the data than before (but note: R-squared values are NOT important for causal interpretations generally).

**TAKEAWAY: Using unit fixed effects in panel data shifts the identifying variation from across units to within units over time.**

## Bringing it all Together with Site-by-Year Fixed Effects

We now combine the plot-fixed-effect-based analyses together. This should give us more statistical power to detect effects. We do want to account for the fact that different sites experience different conditions in different years. To do so in a flexible way, we include site-by-year fixed effects, $\delta_{st}$. 
\begin{equation}
\ln(\text{Live Mass}_{pst}) = \beta \ln(\text{Richness}_{pst}) + \lambda_p + \delta_{st} +  e_{pst}
\end{equation}
These additional fixed effects control for all time-varying effects that impact the site as whole (i.e., that apply to all the plots equally). Thus, they capture the first order effects of weather, among other factors that could shift outcomes for the site as whole.


We will include a couple of time-varying controls. To make sure we don't drop locations with values of zero (but for which we want logged values), we first define the inverse hyperbolic sine. Note that we don't need to worry about that for productivity or richness because they never take a zero value.
```{r message=FALSE, warning=FALSE}

ihs <- function(x) {
  y <- log(x+sqrt(x^2 + 1))
}


MainMod_Rich     <- feols(log(live_mass) ~ log(rich)  | newplotid + site.by.yeardummy, comb) 
MainMod_RichEven <- feols(log(live_mass) ~ log(rich) + ihs(even) | newplotid + site.by.yeardummy, comb) 
MainMod_RichLag  <- feols(log(live_mass) ~ log(rich) + log(laggedrich) | newplotid + site.by.yeardummy, comb) 
MainMod_RichEvenLag <- feols(log(live_mass) ~ log(rich) + log(laggedrich) + ihs(even) | newplotid + site.by.yeardummy, comb)

etable(MainMod_Rich, MainMod_RichEven, MainMod_RichLag, MainMod_RichEvenLag,
          cluster = "newplotid")

```

As you can see, estimate on log richness are relatively stable across different specifications. Of special note: the coefficient on lagged richness (richness last year) is small and insignificant, given us confidence that our results reflect *contemporaneous* movement in richness, and some factor that is also correlated with last year's richness.

**TAKEAWAY: Fixed effects can alter the research design and control for a wide variety of potentially confounding factors!**


FINAL FIGURE HERE WITH SITEYEAR VARIATION REMOVED

# Random Effects Don't Usually Cut It...

Researchers sometimes turn to random effects models. While random effects models have a number of useful properties, they **do not solve endogeneity problems**. Any variable that is omitted from a random effects model is implicitly assumed to either have no effect on productivity or to be uncorrelated with richness. So, random effects on their own don't buy us anything more than conditioning on observables. Check out how the results below vary to see this:

First, consider the two linear models (without random effects) with different sets of soil variables

```{r message=FALSE, warning=FALSE}

## Linear Model with Soil Covariates
SoilCovars <- feols(log(live_mass) ~ log(rich) +
                      pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B, 
                    comb, cluster = "newplotid") 

## Linear Model with More Soil Covariates
SoilCovars_More <- feols(log(live_mass) ~ log(rich) +
                      pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +
                      pH + PercentSand + PercentSilt + PercentClay, 
                    comb, cluster = "newplotid") 

etable(SoilCovars, SoilCovars_More,
          cluster = "newplotid", 
          drop = "!rich", 
          subtitles = c("Some soil covariates","More soil covariates")) 

```

See how the covariate of interest jumps around. Again, that's a reminder that there are likely omitted variables that are pretty correlated with our variable of interest.

So, that's our baseline. Now let's see what happens with random effects! 

```{r message=FALSE, warning=FALSE}

## First, characteristics of soil influence both productivity and richness, including XXXXXX. We can use covariates that characterize several aspects of the soil fertility and nutrients... LAUREN FILL IN HERE: including 
MixedMod_Rich_soil <- lmer(log(live_mass) ~ log(rich) + 
                             pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +   pH + PercentSand + PercentSilt + PercentClay +    (1|newplotid) +   (1|site_code), comb, REML = F)
summary(MixedMod_Rich_soil)


### Based on prior studies and natural history, we would expect management and anthropogenic disturbances to be important confounding variables. The Nutrient Network data has indicator variables .... 
MixedMod_Rich2 <- lmer(log(live_mass) ~ log(rich) + 
                         managed + burned + grazed + anthropogenic + 
                         pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +  ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +   pH + PercentSand + PercentSilt + PercentClay +    (1|newplotid) +                             (1|site_code), comb, REML = F)
summary(MixedMod_Rich2 )


## we build to the model presented in Figure 2B in the main text that includes XXXX variables 
MixedMod_Rich <- lmer(log(live_mass) ~ log(rich) + as.factor(country) + as.factor(habitat) + as.factor(year) + 
                        elevation + managed + burned + grazed + anthropogenic + 
                        TEMP_VAR_v2 + MIN_TEMP_v2 + MAX_TEMP_v2 + TEMP_WET_Q_v2 + TEMP_DRY_Q_v2 + TEMP_WARM_Q_v2 +                            TEMP_COLD_Q_v2 +   pct_C + pct_N + ppm_P + ppm_K + ppm_Na + ppm_Mg + ppm_S + ppm_Na + ppm_Zn +            ppm_Mn +  ppm_Fe + ppm_Cu + ppm_B +   pH + PercentSand + PercentSilt + PercentClay +    (1|newplotid) +                             (1|site_code), comb, REML = F)
summary(MixedMod_Rich )

```

None these models really addresses endogeneity...
